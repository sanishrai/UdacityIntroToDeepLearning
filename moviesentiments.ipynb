{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-26T02:51:03.941357Z","iopub.execute_input":"2021-05-26T02:51:03.941728Z","iopub.status.idle":"2021-05-26T02:51:03.965449Z","shell.execute_reply.started":"2021-05-26T02:51:03.941651Z","shell.execute_reply":"2021-05-26T02:51:03.964459Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/dataset/labels.txt\n/kaggle/input/dataset/reviews.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"with open('../input/dataset/reviews.txt','r') as f:\n    reviews=f.read()\nwith open('../input/dataset/labels.txt','r') as f:\n    labels=f.read()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T02:51:03.966926Z","iopub.execute_input":"2021-05-26T02:51:03.967267Z","iopub.status.idle":"2021-05-26T02:51:04.765663Z","shell.execute_reply.started":"2021-05-26T02:51:03.967232Z","shell.execute_reply":"2021-05-26T02:51:04.764819Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"print(reviews[:2000])\nprint(labels[:5])","metadata":{"execution":{"iopub.status.busy":"2021-05-26T02:51:04.767460Z","iopub.execute_input":"2021-05-26T02:51:04.767831Z","iopub.status.idle":"2021-05-26T02:51:04.773153Z","shell.execute_reply.started":"2021-05-26T02:51:04.767791Z","shell.execute_reply":"2021-05-26T02:51:04.772182Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   \nstory of a man who has unnatural feelings for a pig . starts out with a opening scene that is a terrific example of absurd comedy . a formal orchestra audience is turned into an insane  violent mob by the crazy chantings of it  s singers . unfortunately it stays absurd the whole time with no general narrative eventually making it just too off putting . even those from the era should be turned off . the cryptic dialogue would make shakespeare seem easy to a third grader . on a technical level it  s better than you might think with some good cinematography by future great vilmos zsigmond . future stars sally kirkland and frederic forrest can be seen briefly .  \nhomelessness  or houselessness as george carlin stated  has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school  work  or vote for the matter . most people think of the homeless as just a lost cause while worrying about things such as racism  the war on iraq  pressuring kids to succeed  technology  the elections  inflation  or worrying if they  ll be next to end up on the streets .  br    br   but what if y\nposit\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data preprocessing","metadata":{}},{"cell_type":"code","source":"from string import punctuation\nprint(punctuation)\nreviews = reviews.lower()\nall_text = ''.join([c for c in reviews if c not in punctuation])\n# print(all_text[:100])\nreviews_split = all_text.split('\\n')\nall_text=''.join(reviews_split)\nwords=all_text.split()#default separator is the white space\n# print(words[:20])\n","metadata":{"execution":{"iopub.status.busy":"2021-05-26T02:51:04.774870Z","iopub.execute_input":"2021-05-26T02:51:04.775419Z","iopub.status.idle":"2021-05-26T02:51:08.108677Z","shell.execute_reply.started":"2021-05-26T02:51:04.775381Z","shell.execute_reply":"2021-05-26T02:51:08.107765Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(words))","metadata":{"execution":{"iopub.status.busy":"2021-05-26T02:51:08.110024Z","iopub.execute_input":"2021-05-26T02:51:08.110375Z","iopub.status.idle":"2021-05-26T02:51:08.115496Z","shell.execute_reply.started":"2021-05-26T02:51:08.110338Z","shell.execute_reply":"2021-05-26T02:51:08.114591Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"6020196\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Encoding the words","metadata":{}},{"cell_type":"code","source":"from collections import Counter\n## Build a dictionary that maps words to integers\nvocab = (Counter(words))\nvocab = sorted(vocab, key=vocab.get, reverse=True)\n\n# print(len(vocab))\nint_to_vocab = dict(enumerate(vocab))\nvocab_to_int = {v:ii+1 for ii,v in int_to_vocab.items()}\n# print(vocab_to_int)\n\n## use the dict to tokenize each review in reviews_split\n## store the tokenized reviews in reviews_ints\nreviews_ints = []\nfor review in reviews_split:\n    reviews_ints.append([vocab_to_int[word] for word in review.split()])","metadata":{"execution":{"iopub.status.busy":"2021-05-26T02:51:08.116958Z","iopub.execute_input":"2021-05-26T02:51:08.117313Z","iopub.status.idle":"2021-05-26T02:51:10.202487Z","shell.execute_reply.started":"2021-05-26T02:51:08.117278Z","shell.execute_reply":"2021-05-26T02:51:10.201597Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# print(reviews_ints[:1])\nprint(vocab_to_int['the'])","metadata":{"execution":{"iopub.status.busy":"2021-05-26T02:51:10.203808Z","iopub.execute_input":"2021-05-26T02:51:10.204193Z","iopub.status.idle":"2021-05-26T02:51:10.208897Z","shell.execute_reply.started":"2021-05-26T02:51:10.204156Z","shell.execute_reply":"2021-05-26T02:51:10.207955Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"1\n","output_type":"stream"}]},{"cell_type":"code","source":"#encoding the labels now\nlabels_split=labels.split('\\n')\nencoded_labels = np.array([1 if label =='positive' else 0 for label in labels_split])\n# print(encoded_labels[10])","metadata":{"execution":{"iopub.status.busy":"2021-05-26T02:51:10.211492Z","iopub.execute_input":"2021-05-26T02:51:10.211835Z","iopub.status.idle":"2021-05-26T02:51:10.228727Z","shell.execute_reply.started":"2021-05-26T02:51:10.211798Z","shell.execute_reply":"2021-05-26T02:51:10.227899Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#removing outliers\nreview_lens = Counter([len(x) for x in reviews_ints])\nprint(\"Zero-length reviews: {}\".format(review_lens[0]))\nprint(\"Maximum review length: {}\".format(max(review_lens)))","metadata":{"execution":{"iopub.status.busy":"2021-05-26T02:51:10.230433Z","iopub.execute_input":"2021-05-26T02:51:10.230789Z","iopub.status.idle":"2021-05-26T02:51:10.241836Z","shell.execute_reply.started":"2021-05-26T02:51:10.230745Z","shell.execute_reply":"2021-05-26T02:51:10.240887Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Zero-length reviews: 1\nMaximum review length: 2514\n","output_type":"stream"}]},{"cell_type":"code","source":"print('Number of reviews before removing outliers:',len(reviews_ints))\nnon_zero_idx = [ii for ii, review in enumerate(reviews_ints) if len(review)!=0]\nreviews_ints =[reviews_ints[ii] for ii in non_zero_idx]\nencoded_labels = np.array([encoded_labels[ii]for ii in non_zero_idx])\nprint('Number of reviews after removing outliers: ', len(reviews_ints))\n","metadata":{"execution":{"iopub.status.busy":"2021-05-26T02:51:10.243234Z","iopub.execute_input":"2021-05-26T02:51:10.243593Z","iopub.status.idle":"2021-05-26T02:51:10.267522Z","shell.execute_reply.started":"2021-05-26T02:51:10.243556Z","shell.execute_reply":"2021-05-26T02:51:10.266554Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Number of reviews before removing outliers: 25001\nNumber of reviews after removing outliers:  25000\n","output_type":"stream"}]},{"cell_type":"code","source":"def pad_features(reviews_ints, seq_length):\n    features = np.zeros((len(reviews_ints),seq_length),dtype=int)\n    for i, row in enumerate(reviews_ints):\n        features[i,-len(row):]=np.array(row)[:seq_length]\n    return features\n        \n    ","metadata":{"execution":{"iopub.status.busy":"2021-05-26T02:51:10.268979Z","iopub.execute_input":"2021-05-26T02:51:10.269376Z","iopub.status.idle":"2021-05-26T02:51:10.277257Z","shell.execute_reply.started":"2021-05-26T02:51:10.269339Z","shell.execute_reply":"2021-05-26T02:51:10.276452Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"x=np.array([[1,2,3,4,5],[6,7,8,9,10],[11,12,13,14,15]])\ny=[1,2,3,4]\n# print(x[:,-3:],'\\n')\n# print(x[:,-3])\n# print(y[1:4:2])\nfeatures = np.zeros((len(x),2),dtype=int)\n# print(featu/res[1,1])\nz = np.array(x)[:2]\nprint(z)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-26T02:51:10.278578Z","iopub.execute_input":"2021-05-26T02:51:10.279157Z","iopub.status.idle":"2021-05-26T02:51:10.288247Z","shell.execute_reply.started":"2021-05-26T02:51:10.279122Z","shell.execute_reply":"2021-05-26T02:51:10.287297Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"[[ 1  2  3  4  5]\n [ 6  7  8  9 10]]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Test your implementation!\n\nseq_length = 200\n\nfeatures = pad_features(reviews_ints, seq_length=seq_length)\n\n## test statements - do not change - ##\nassert len(features)==len(reviews_ints), \"Your features should have as many rows as reviews.\"\nassert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n\n# print first 10 values of the first 30 batches \n#print(features[:30,:10])","metadata":{"execution":{"iopub.status.busy":"2021-05-26T02:51:10.289804Z","iopub.execute_input":"2021-05-26T02:51:10.290188Z","iopub.status.idle":"2021-05-26T02:51:11.386169Z","shell.execute_reply.started":"2021-05-26T02:51:10.290141Z","shell.execute_reply":"2021-05-26T02:51:11.385313Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"\nTraining, Validation, Test\nWith our data in nice shape, we'll split it into training, validation, and test sets.\n\nExercise: Create the training, validation, and test sets.\n\nYou'll need to create sets for the features and the labels, train_x and train_y, for example.\nDefine a split fraction, split_frac as the fraction of data to keep in the training set. Usually this is set to 0.8 or 0.9.\nWhatever data is left will be split in half to create the validation and testing data.","metadata":{}},{"cell_type":"code","source":"split_frac = 0.8\n\n## split data into training, validation, and test data (features and labels, x and y)\nsplit_idx=int(len(features)*split_frac)\ntrain_x, remaining_x = features[:split_idx],features[split_idx:]\ntrain_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n\ntest_idx = int(len(remaining_x)*0.5)\nval_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\nval_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n## print out the shapes of your resultant feature data\nprint(\"\\t\\t\\tFeature Shapes:\")\nprint(\"Train set: \\t\\t{}\".format(train_x.shape), \n      \"\\nValidation set: \\t{}\".format(val_x.shape),\n      \"\\nTest set: \\t\\t{}\".format(test_x.shape))","metadata":{"execution":{"iopub.status.busy":"2021-05-26T02:51:11.387400Z","iopub.execute_input":"2021-05-26T02:51:11.387750Z","iopub.status.idle":"2021-05-26T02:51:11.395589Z","shell.execute_reply.started":"2021-05-26T02:51:11.387712Z","shell.execute_reply":"2021-05-26T02:51:11.394756Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"\t\t\tFeature Shapes:\nTrain set: \t\t(20000, 200) \nValidation set: \t(2500, 200) \nTest set: \t\t(2500, 200)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import TensorDataset, DataLoader\n\n#create tensor datasets\ntrain_data = TensorDataset(torch.from_numpy(train_x),torch.from_numpy(train_y))\nvalid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\ntest_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n\n#data loaders\nbatch_size=50\ntrain_loader = DataLoader(train_data,shuffle=True, batch_size=batch_size)\nvalid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\ntest_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T02:51:11.396754Z","iopub.execute_input":"2021-05-26T02:51:11.397270Z","iopub.status.idle":"2021-05-26T02:51:12.636392Z","shell.execute_reply.started":"2021-05-26T02:51:11.397234Z","shell.execute_reply":"2021-05-26T02:51:12.635354Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"sample_x, sample_y = next(iter(train_loader))\n\nprint('Sample input size: ', sample_x.size()) # batch_size, seq_length\nprint('Sample input: \\n', sample_x)\nprint()\nprint('Sample label size: ', sample_y.size()) # batch_size\nprint('Sample label: \\n', sample_y)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T02:51:12.637629Z","iopub.execute_input":"2021-05-26T02:51:12.637986Z","iopub.status.idle":"2021-05-26T02:51:12.680904Z","shell.execute_reply.started":"2021-05-26T02:51:12.637947Z","shell.execute_reply":"2021-05-26T02:51:12.679918Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Sample input size:  torch.Size([50, 200])\nSample input: \n tensor([[   11,    18,   489,  ...,    47,  1894,   123],\n        [    0,     0,     0,  ..., 18536,  1367,    21],\n        [    0,     0,     0,  ...,   543,     7,     7],\n        ...,\n        [  998,  1217,   437,  ...,   312,  5124,    13],\n        [    0,     0,     0,  ...,     6,   179,   924],\n        [    0,     0,     0,  ...,  1777,     1,   687]])\n\nSample label size:  torch.Size([50])\nSample label: \n tensor([0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n        0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n        1, 1])\n","output_type":"stream"}]},{"cell_type":"code","source":"# First checking if GPU is available\ntrain_on_gpu=torch.cuda.is_available()\n\nif(train_on_gpu):\n    print('Training on GPU.')\nelse:\n    print('No GPU available, training on CPU.')","metadata":{"execution":{"iopub.status.busy":"2021-05-26T02:51:12.682318Z","iopub.execute_input":"2021-05-26T02:51:12.682907Z","iopub.status.idle":"2021-05-26T02:51:12.762385Z","shell.execute_reply.started":"2021-05-26T02:51:12.682869Z","shell.execute_reply":"2021-05-26T02:51:12.761169Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Training on GPU.\n","output_type":"stream"}]},{"cell_type":"code","source":"#Model\nimport torch.nn as nn\nclass SentimentRNN(nn.Module):\n    def __init__(self,vocab_size, output_size, embedding_dim,hidden_dim,n_layers, drop_prob=0.5):\n        super().__init__()\n        self.output_size=output_size\n        self.n_layers=n_layers\n        self.hidden_dim=hidden_dim\n        self.embedding_dim =embedding_dim\n        \n        self.embedding = nn.Embedding(vocab_size,embedding_dim)\n        \n        self.lstm = nn.LSTM(embedding_dim,hidden_dim,n_layers,\n                           dropout=drop_prob, batch_first=True)\n        \n        self.dropout = nn.Dropout(drop_prob)\n        self.fc = nn.Linear(hidden_dim,output_size)\n        self.sig = nn.Sigmoid()\n        \n    def forward(self,x,hidden):\n        batch_size = x.size(0)\n        x=x.long()\n        embeds = self.embedding(x)\n        r_output, hidden = self.lstm(embeds,hidden)\n        r_output = r_output[:,-1,:]#geting the last time step output\n        out = self.dropout(r_output)\n#         out = out.contiguous().view(-1,self.hidden_dim)\n        out = self.fc(out)\n        sig_out=self.sig(out)\n        return sig_out, hidden\n    def init_hidden(self, batch_size):\n        '''' Initializes hidden state '''\n        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n        # initialized to zero, for hidden state and cell state of LSTM\n        weight = next(self.parameters()).data\n        if (train_on_gpu):\n            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n        else:\n            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n        return hidden\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2021-05-26T02:55:14.420214Z","iopub.execute_input":"2021-05-26T02:55:14.420517Z","iopub.status.idle":"2021-05-26T02:55:14.432163Z","shell.execute_reply.started":"2021-05-26T02:55:14.420491Z","shell.execute_reply":"2021-05-26T02:55:14.430125Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"execution":{"iopub.status.busy":"2021-05-26T02:51:56.237783Z","iopub.execute_input":"2021-05-26T02:51:56.238125Z","iopub.status.idle":"2021-05-26T02:51:57.541834Z","shell.execute_reply.started":"2021-05-26T02:51:56.238095Z","shell.execute_reply":"2021-05-26T02:51:57.540114Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"SentimentRNN(\n  (embedding): Embedding(74073, 400)\n  (lstm): LSTM(74073, 256, num_layers=2, batch_first=True, dropout=0.5)\n  (dropout): Dropout(p=0.5, inplace=False)\n  (fc): Linear(in_features=256, out_features=1, bias=True)\n  (sig): Sigmoid()\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"#instantiate the network\nvocab_size=len(vocab_to_int)+1\noutput_size=1\nembedding_dim=400\nhidden_dim=256\nn_layers=2\nnet=SentimentRNN(vocab_size,output_size,embedding_dim,hidden_dim,n_layers)\nlr=0.001\ncriterion=nn.BCELoss()\noptimizer=torch.optim.Adam(net.parameters(),lr=lr)\n\nepochs=4\ncounter=0\nprint_every=100\nclip=5\n\nif(train_on_gpu):\n    net.cuda()\n\nnet.train()\nfor e in range(epochs):\n#     net.train()\n    h=net.init_hidden(batch_size)\n    for inputs,labels in train_loader:\n        net.train()\n        counter+=1\n        if(train_on_gpu):\n            inputs,labels = inputs.cuda(), labels.cuda()\n        h=tuple([each.data for each in h])\n        net.zero_grad()\n        output,h = net(inputs,h)\n        loss = criterion(output.squeeze(),labels.float())\n        loss.backward()\n        \n        nn.utils.clip_grad_norm_(net.parameters(),clip)\n        optimizer.step()\n        \n        if counter % print_every==0:\n            #get validation loss\n            val_h=net.init_hidden(batch_size)\n            val_losses=[]\n            net.eval()\n            for inputs,labels in valid_loader:\n                if(train_on_gpu):\n                    inputs,labels = inputs.cuda(), labels.cuda()\n                h=tuple([each.data for each in val_h])\n                output,h=net(inputs,h)\n                val_loss=criterion(output.squeeze(),labels.float())\n                val_losses.append( val_loss.item())\n            \n            print(\"Epoch:{}/{}...\".format(e+1,epochs),\n                       \"Step:{}...\".format(counter),\n                       \"Loss:{:.6f}...\".format(loss.item()),\n                       \"Val loss: {:.6f}\".format(np.mean(val_losses))\n                      )    \n         \n","metadata":{"execution":{"iopub.status.busy":"2021-05-26T02:56:49.136657Z","iopub.execute_input":"2021-05-26T02:56:49.137002Z","iopub.status.idle":"2021-05-26T02:58:14.093778Z","shell.execute_reply.started":"2021-05-26T02:56:49.136972Z","shell.execute_reply":"2021-05-26T02:58:14.092911Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Epoch:1/4... Step:100... Loss:0.642509... Val loss: 0.655525\nEpoch:1/4... Step:200... Loss:0.500495... Val loss: 0.630297\nEpoch:1/4... Step:300... Loss:0.611518... Val loss: 0.584168\nEpoch:1/4... Step:400... Loss:0.522333... Val loss: 0.543917\nEpoch:2/4... Step:500... Loss:0.444236... Val loss: 0.476116\nEpoch:2/4... Step:600... Loss:0.384349... Val loss: 0.449689\nEpoch:2/4... Step:700... Loss:0.486675... Val loss: 0.464213\nEpoch:2/4... Step:800... Loss:0.412699... Val loss: 0.446014\nEpoch:3/4... Step:900... Loss:0.503199... Val loss: 0.579040\nEpoch:3/4... Step:1000... Loss:0.286742... Val loss: 0.494151\nEpoch:3/4... Step:1100... Loss:0.280538... Val loss: 0.413395\nEpoch:3/4... Step:1200... Loss:0.178616... Val loss: 0.441001\nEpoch:4/4... Step:1300... Loss:0.115510... Val loss: 0.519348\nEpoch:4/4... Step:1400... Loss:0.211640... Val loss: 0.459530\nEpoch:4/4... Step:1500... Loss:0.149693... Val loss: 0.483193\nEpoch:4/4... Step:1600... Loss:0.161172... Val loss: 0.488136\n","output_type":"stream"}]},{"cell_type":"code","source":"# Get test data loss and accuracy\n\ntest_losses = [] # track loss\nnum_correct = 0\n\n# init hidden state\nh = net.init_hidden(batch_size)\n\nnet.eval()\n# iterate over test data\nfor inputs, labels in test_loader:\n\n    # Creating new variables for the hidden state, otherwise\n    # we'd backprop through the entire training history\n    h = tuple([each.data for each in h])\n\n    if(train_on_gpu):\n        inputs, labels = inputs.cuda(), labels.cuda()\n\n    # get predicted outputs\n    output, h = net(inputs, h)\n\n    # calculate loss\n    test_loss = criterion(output.squeeze(), labels.float())\n    test_losses.append(test_loss.item())\n\n    # convert output probabilities to predicted class (0 or 1)\n    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n\n    # compare predictions to true label\n    correct_tensor = pred.eq(labels.float().view_as(pred))\n    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n    num_correct += np.sum(correct)\n\n\n# -- stats! -- ##\n# avg test loss\nprint(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n\n# accuracy over all test data\ntest_acc = num_correct/len(test_loader.dataset)\nprint(\"Test accuracy: {:.3f}\".format(test_acc))","metadata":{"execution":{"iopub.status.busy":"2021-05-26T03:23:32.691966Z","iopub.execute_input":"2021-05-26T03:23:32.692340Z","iopub.status.idle":"2021-05-26T03:23:33.321431Z","shell.execute_reply.started":"2021-05-26T03:23:32.692309Z","shell.execute_reply":"2021-05-26T03:23:33.320331Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Test loss: 0.487\nTest accuracy: 0.804\n","output_type":"stream"}]},{"cell_type":"code","source":"# negative test review\ntest_review_neg = \"The best movie I have seen; acting was good and I loved it.\"\nfrom string import punctuation\n\ndef tokenize_review(test_review):\n    test_review = test_review.lower() # lowercase\n    # get rid of punctuation\n    test_text = ''.join([c for c in test_review if c not in punctuation])\n\n    # splitting by spaces\n    test_words = test_text.split()\n\n    # tokens\n    test_ints = []\n    test_ints.append([vocab_to_int.get(word, 0) for word in test_words])\n\n    return test_ints\n\n# test code and generate tokenized review\ntest_ints = tokenize_review(test_review_neg)\nprint(test_ints)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-26T03:28:43.640634Z","iopub.execute_input":"2021-05-26T03:28:43.640977Z","iopub.status.idle":"2021-05-26T03:28:43.647833Z","shell.execute_reply.started":"2021-05-26T03:28:43.640948Z","shell.execute_reply":"2021-05-26T03:28:43.646784Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"[[1, 117, 18, 10, 28, 108, 113, 14, 50, 2, 10, 445, 8]]\n","output_type":"stream"}]},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"# test sequence padding\nseq_length=200\nfeatures = pad_features(test_ints, seq_length)\n\nprint(features)\n# test conversion to tensor and pass into your model\nfeature_tensor = torch.from_numpy(features)\nprint(feature_tensor.size())","metadata":{"execution":{"iopub.status.busy":"2021-05-26T03:28:47.928380Z","iopub.execute_input":"2021-05-26T03:28:47.928688Z","iopub.status.idle":"2021-05-26T03:28:47.934757Z","shell.execute_reply.started":"2021-05-26T03:28:47.928660Z","shell.execute_reply":"2021-05-26T03:28:47.933927Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   1 117  18  10  28 108 113  14  50   2  10\n  445   8]]\ntorch.Size([1, 200])\n","output_type":"stream"}]},{"cell_type":"code","source":"def predict(net, test_review, sequence_length=200):\n    \n    net.eval()\n    \n    # tokenize review\n    test_ints = tokenize_review(test_review)\n    \n    # pad tokenized sequence\n    seq_length=sequence_length\n    features = pad_features(test_ints, seq_length)\n    \n    # convert to tensor to pass into your model\n    feature_tensor = torch.from_numpy(features)\n    \n    batch_size = feature_tensor.size(0)\n    \n    # initialize hidden state\n    h = net.init_hidden(batch_size)\n    \n    if(train_on_gpu):\n        feature_tensor = feature_tensor.cuda()\n    \n    # get the output from the model\n    output, h = net(feature_tensor, h)\n    \n    # convert output probabilities to predicted class (0 or 1)\n    pred = torch.round(output.squeeze()) \n    # printing output value, before rounding\n    print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n    \n    # print custom response\n    if(pred.item()==1):\n        print(\"Positive review detected!\")\n    else:\n        print(\"Negative review detected.\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T03:25:53.352017Z","iopub.execute_input":"2021-05-26T03:25:53.352333Z","iopub.status.idle":"2021-05-26T03:25:53.359622Z","shell.execute_reply.started":"2021-05-26T03:25:53.352307Z","shell.execute_reply":"2021-05-26T03:25:53.358589Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"predict(net, test_review_neg, seq_length)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-26T03:28:51.952089Z","iopub.execute_input":"2021-05-26T03:28:51.952408Z","iopub.status.idle":"2021-05-26T03:28:51.965443Z","shell.execute_reply.started":"2021-05-26T03:28:51.952382Z","shell.execute_reply":"2021-05-26T03:28:51.964482Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Prediction value, pre-rounding: 0.989749\nPositive review detected!\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}